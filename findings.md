# Findings & Research

## Requirements (Confirmed)
- **Model:** Llama 3.2 (via Ollama).
- **Interface:** Streamlit Chat UI.
- **Core Logic:** Use a stored "Proper Template" to guide generation.
- **Output:** Test cases generated in the UI.

## Technology Decisions
- **Frontend:** Streamlit (`pip install streamlit`) - best for "UI Chat" in Python.
- **LLM Client:** `ollama` python library.

